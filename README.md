# README

# Quick-start
Executing [`run.sh`](src/run.sh) runs the pipeline outlind below. Briefly, it
1. Retrieves the required pre-built singularity image 
2. Defines input/output parameters
3. Executes the processing script [`processing.R`](src/processing.R) within a singularity container

# In greater detail
## Retrieve singularity image
[`run.sh`](src/run.sh) first retrieves the singularity image (currently stored on onedrive for
direct download using `wget`) if it does not exist.
```bash
img='r-4.0'
id='77DD71E598E5B51B'
auth='AJdCAAZQQrCo9cc'
if [ ! -f ${img}.sif ]; then
    wget -O ${img}.sif \
        "https://onedrive.live.com/download?cid=${id}&resid=${id}%2124983&authkey=${auth}"
fi
```

The image was built from [`r-4.0.singularity`](src/r-4.0.singularity) using the sylabs remote 
builder, i.e.:

```bash
singularity build --remote src/${img}.sif src/${img}.singularity
```

# DIA-NN singularity image

The image was built from the recipe file [`diann-1.8.1.def`](src/diann-1.8.1.def) using the sylabs
remote builder (via web interface).
```bash
md5_desired='35644c1d7217f0c65727b8fb9c8bfaae'

module load singularity
singularity pull \
    --arch amd64 \
    --name src/diann-1.8.1.sif \
    library://wellerca/diann/1.8.1:0.9

md5_actual=$(md5sum src/diann-1.8.1.sif | awk '{print $1}')

if [ ! "${md5_actual}" == "${md5_desired}" ]; then
    echo  'sif md5 does not match'
else
    echo 'sif md5 verified'
fi
```
Note: The container must be called using the `--cleanenv` option, otherwise the container may fail 
due to collision between system and container libraries.

Testing a run that's submitted to biowulf with the [`run-diann.sh`](src/run-diann.sh) wrapper:

```bash
sbatch src/run-diann.sh \
    --mzml ./example/raw_MS_mzML/HREC_ETIS_1.mzML \
    --fasta ./example/uniprot-proteome_Human_UP000005640_20191105.fasta
```

## Running the processing R script
After ensuring the singularity image is available, [`run.sh`](src/run.sh) defines input/output
parameters and executes [`processing.R`](src/processing.R) within the container, generating
plots or tables within the defined output directories.

```bash
pro_input='input/spe_Report_Proteins.csv' #csv of the protein groups quntification generated by SN
project_name='test' #the name of this project
outdir='./output' #output dir
design_matrix='input/design_matrix.csv' #csv file of design matrix for comparison
r_script='processing.R'

# unused / NYI:
# pep_input='' #the csv file of the peptide intensity from the SN
# normalization='' # 'T' or 'F'

module load singularity

singularity run -H $PWD:/home src/${img}.sif \
    Rscript src/${r_script} \
    --pro_input ${pro_input} \
    -p ${project_name} \
    -o ${outdir} \
    --design_matrix ${design_matrix}
```




## Proteomics data anylysis 

This workflow performs the following tasks:
- [Spectronaut](https://biognosys.com/resources/spectronaut-the-deepest-proteome-coverage-available/) or [DIA-NN](https://github.com/vdemichev/DiaNN) for Protein Analysis and Quantification
- Quality control and data filltering
- Normalization and imputation(OPTIONAL)
- Data Cluster
- Differential expression analysis and visualization
- Downstream functional enrichment analysis
- Run all steps from start to finish

## System requirements
- Windows for Spectronaut
- Linux for DIA-NN
- R 


## Spectronaut for Protein Analysis and Quantification
We uses the Spectronaut software for protein analysis and quantification in Windows systerm.

## DIA-NN for Protein Analysis and Quantification
We uses the DIA-NN software for protein analysis and quantification on biowulf or Windows systerm.

Use the following commands to run DIA-NN on prebuilt module on biowulfï¼š
``` bash
# TODO: change diann to work as singularity container
module load diann
diann \
    --f ../20210208_KLOF_DIA_FAIMS_35V_d0_1.mzML   \
    --lib  \
    --threads 24 \
    --verbose 1 \
    --out ./report.tsv \
    --qvalue 0.01 \
    --matrices \
    --out-lib ./report-lib.tsv \
    --gen-spec-lib \
    --predictor \
    --fasta ../uniprot-proteome_Human_UP000005640_20191105.fasta \
    --fasta-search \
    --min-fr-mz 200 \
    --max-fr-mz 2000 \
    --met-excision \
    --cut K*,R* \
    --missed-cleavages 2 \
    --min-pep-len 7 \
    --max-pep-len 52 \
    --min-pr-mz 300 \
    --max-pr-mz 1800 \
    --min-pr-charge 1 \
    --max-pr-charge 4 \
    --unimod4 \
    --var-mods 5 \
    --var-mod UniMod:35,15.994915,M \
    --var-mod UniMod:1,42.010565,*n \
    --monitor-mod UniMod:1 \
    --reanalyse \
    --relaxed-prot-inf \
    --smart-profiling \
    --peak-center \
    --no-ifs-removal  \
``` 

## Quality control and data filltering
We used the R to process the MS data, visualize the samples quality and fillter some sample with poor quality. This step will provide the figures including the total number of identified and quantified protein groups, the distribution of protein intensity, and correlation among protein abundance of the biological replicates.

Runing the code:
``` bash
# QC.R does not exist
Rscript src/QC.R \
    --pro_input $pro_input \
    --pep_input $pep_input \
    -p $project_name \
    -o $outdir
``` 

## Data Cluster
The data cluster include HC-cluster, PCA, and UMAP.

``` bash
# TODO: cluster_plot.R renamed cluster.R?
Rscript cluster_plot.R -i $pro_input -p $project_name -o $outdir
``` 


## Differential expression analysis(T-test) and downstream functional enrichment analysis
DE analysis is done using the t-test. Downstream functional enrichment analysis for Differential expression gene. It takes the MS quatification from Spectronaut as an input:
```
# TODO: DE_enrichment.R does not exist
Rscript DE_enrichment.R -i $pro_input -c $control -o $outdir 
```

## Bash comand line

```
# TODO: spe_pro.bash does not exist
bash spe_pro.bash
```


## Tiny example

### Generating tiny example files
Wanting to subset down to 5% of FASTA file and 1% of mzML file. Subsetting the fasta is easy.
`wc -l example/uniprot-proteome_Human_UP000005640_20191105.fasta` yields 539137 lines. First 4999
lines evenly splits between entries, and is ~1% of the file.

```bash
head -n 4999 example/uniprot-proteome_Human_UP000005640_20191105.fasta > tiny/tiny.fasta
```

Splitting the mzML file is more difficult due to XML formatting. One of the files 
`example/uniprot-proteome_Human_UP000005640_20191105.fasta` contains 78301 `<pectrum index>` fields.
We can subset by excluding the lines for 99% of the indices. If we only want ~700 of the indices,
we exclude indices 701-78301. Each field ends with a `</spectrum>` tag.

Based on pattern finding and line numbers, we want lines 1-(line BEFORE index 701, i.e. `<`) and from
(line CONTAINING `</spectrumList>`, i.e. `>=`) through EOF.

```bash
lower=$(grep -n '<spectrum index="701"' example/raw_MS_mzML/HREC_IRIS_1.mzML | cut -d ':' -f 1)
upper=$(grep -n '</spectrumList>' example/raw_MS_mzML/HREC_IRIS_1.mzML | cut -d ':' -f 1)
awk -v lower=${lower} \
    -v upper=${upper} \
    'NR < lower || NR >= upper' example/raw_MS_mzML/HREC_IRIS_1.mzML \
    > tiny/tiny.mxML
```

### Test run with container
```bash
src/tiny-diann-test.sh tiny/tiny.mxML tiny/tiny.fasta 
```
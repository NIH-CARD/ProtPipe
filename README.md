# README

![workflow-image](src/workflow.png)

This repository facilitates quick, simple, and reproducible access to Data Independent Acquisition (DIA) proteomics workflows with minimal command line experience.

We include a convenient wrapper script for running DIA-NN inside a pre-built singularity image to first estimate protein abundance from raw mass spec output. Protein abundance estimates (accepting estimates from both `DIA-NN` and `Spectronaut`) can  be processed in a preconfigured R environment, generating QC reports, and various analyses and visualizations.


# Quick-start

1. Ensure `singularity` is installed and accessible on your system. Many HPCs (including NIH Biowulf) come with this pre-installed as a module. If your HPC has singularity installed, it will be automatically detected and loaded when necessary.
2. If you are predicting protein abundances from raw mass spec output, look over and edit any custom `DIA-NN` parameters inside [`config.txt`](config.txt). You can either edit `config.txt` directly (and it will be used by default), or make a copy and save it to a different file name, then reference it with `--config newfilename.txt` when running the wrapper script.
3. Use the wrapper [`run-diann.sh`](src/run-diann.sh), either submitting to SLURM or running it directly.
4. R processing TBI

```bash
# Run directly
src/run-diann.sh \
    --fasta infile.fasta \
    --mzml infile.mzml \
    --out run_output &

# Submit to SLURM
sbatch src/run-diann.sh \
    --fasta infile.fasta \
    --mzml infile.mzml \
    --out run_output &
```


<details><summary>Technical</summary>
The only installation requirement is to have `Singularity` available on your system.

`Singularity` is containerization software that allows an entire pre-configured computing environment to be accessed--reducing installation headaches and improving reproducibility.

# Requirements

# Installation

</details>
<details><summary>notes</summary>


Executing [`run.sh`](src/run.sh) runs the pipeline outlind below. Briefly, it
1. Retrieves the required pre-built singularity image 
2. Defines input/output parameters
3. Executes the processing script [`processing.R`](src/processing.R) within a singularity container

# Notes
Expect ~2 hours of runtime per sample with 20 cores

The output files of interest are
| Filename                  | Description |
| --------                  | ----------- |
| `<specfile>.quant`        | ?? |
| `report-lib.tsv`          | ?? |
| `report-lib.tsv.speclib`  | ?? |
| `report.pr_matrix.tsv`    | precursor ion quantities |
| `report.pg_matrix.tsv`    | protein group quantities |
| `report.gg_matrix.tsv`    | gene group quantities |
| `report.stats.tsv`        | gene group quantities |
| `report.tsv.tsv`          |  precursor ions identified, quantities, quality metrics and annotations |

---
</details>


<details><summary>Running DIA-NN</summary>

## Running DIA-NN on example data
```bash
# Submit to SLURM
sbatch src/run-diann.sh \
    --config config.txt \
    --mzml ./example/raw_MS_mzML/HREC_ETIS_1.mzML \
    --fasta ./example/uniprot-proteome_Human_UP000005640_20191105.fasta \
    --out example/

# Run Locally
src/run-diann.sh \
    --config config.txt \
    --mzml ./example/raw_MS_mzML/HREC_ETIS_1.mzML \
    --fasta ./example/uniprot-proteome_Human_UP000005640_20191105.fasta \
    --out example/
```

</details>

<details><summary>DIA Analysis</summary>

# Heading
1. Foo
2. Bar
    * Baz
    * Qux

</details>

<details><summary>More</summary>

---

# In Greater Detail
Testing a run that's submitted to biowulf with the [`run-diann.sh`](src/run-diann.sh) wrapper:



sbatch src/run-diann.sh \
    --mzml ./example/raw_MS_mzML/HREC_ETIS_1.mzML \
    --fasta ./example/uniprot-proteome_Human_UP000005640_20191105.fasta \
    --config config.txt \
    --clobber \
    --out ./example




## Running the processing R script
After ensuring the singularity image is available, [`run.sh`](src/run.sh) defines input/output
parameters and executes [`processing.R`](src/processing.R) within the container, generating
plots or tables within the defined output directories.

```bash
pro_input='input/spe_Report_Proteins.csv' #csv of the protein groups quntification generated by SN
project_name='test' #the name of this project
outdir='./output' #output dir
design_matrix='input/design_matrix.csv' #csv file of design matrix for comparison
r_script='processing.R'

# unused / NYI:
# pep_input='' #the csv file of the peptide intensity from the SN
# normalization='' # 'T' or 'F'

module load singularity

singularity run -H $PWD:/home src/${img}.sif \
    Rscript src/${r_script} \
    --pro_input ${pro_input} \
    -p ${project_name} \
    -o ${outdir} \
    --design_matrix ${design_matrix}
```




## Proteomics data anylysis 

This workflow performs the following tasks:
- [Spectronaut](https://biognosys.com/resources/spectronaut-the-deepest-proteome-coverage-available/) or [DIA-NN](https://github.com/vdemichev/DiaNN) for Protein Analysis and Quantification
- Quality control and data filltering
- Normalization and imputation(OPTIONAL)
- Data Cluster
- Differential expression analysis and visualization
- Downstream functional enrichment analysis
- Run all steps from start to finish

## System requirements
- Windows for Spectronaut
- Linux for DIA-NN
- R 


## Spectronaut for Protein Analysis and Quantification
We uses the Spectronaut software for protein analysis and quantification in Windows systerm.

## DIA-NN for Protein Analysis and Quantification
We uses the DIA-NN software for protein analysis and quantification on biowulf or Windows systerm.

Use the following commands to run DIA-NN on prebuilt module on biowulfï¼š
``` bash
# TODO: change diann to work as singularity container
module load diann
diann \
    --f ../20210208_KLOF_DIA_FAIMS_35V_d0_1.mzML   \
    --lib  \
    --threads 24 \
    --verbose 1 \
    --out ./report.tsv \
    --qvalue 0.01 \
    --matrices \
    --out-lib ./report-lib.tsv \
    --gen-spec-lib \
    --predictor \
    --fasta ../uniprot-proteome_Human_UP000005640_20191105.fasta \
    --fasta-search \
    --min-fr-mz 200 \
    --max-fr-mz 2000 \
    --met-excision \
    --cut K*,R* \
    --missed-cleavages 2 \
    --min-pep-len 7 \
    --max-pep-len 52 \
    --min-pr-mz 300 \
    --max-pr-mz 1800 \
    --min-pr-charge 1 \
    --max-pr-charge 4 \
    --unimod4 \
    --var-mods 5 \
    --var-mod UniMod:35,15.994915,M \
    --var-mod UniMod:1,42.010565,*n \
    --monitor-mod UniMod:1 \
    --reanalyse \
    --relaxed-prot-inf \
    --smart-profiling \
    --peak-center \
    --no-ifs-removal  \
``` 

## Quality control and data filltering
We used the R to process the MS data, visualize the samples quality and fillter some sample with poor quality. This step will provide the figures including the total number of identified and quantified protein groups, the distribution of protein intensity, and correlation among protein abundance of the biological replicates.

Runing the code:
``` bash
# QC.R does not exist
Rscript src/QC.R \
    --pro_input $pro_input \
    --pep_input $pep_input \
    -p $project_name \
    -o $outdir
``` 

## Data Cluster
The data cluster include HC-cluster, PCA, and UMAP.

``` bash
# TODO: cluster_plot.R renamed cluster.R?
Rscript cluster_plot.R -i $pro_input -p $project_name -o $outdir
``` 


## Differential expression analysis(T-test) and downstream functional enrichment analysis
DE analysis is done using the t-test. Downstream functional enrichment analysis for Differential expression gene. It takes the MS quatification from Spectronaut as an input:
```
# TODO: DE_enrichment.R does not exist
Rscript DE_enrichment.R -i $pro_input -c $control -o $outdir 
```

## Bash comand line

```
# TODO: spe_pro.bash does not exist
bash spe_pro.bash
```


## Tiny example

### Generating tiny example files
Wanting to subset down to 5% of FASTA file and 1% of mzML file. Subsetting the fasta is easy.
`wc -l example/uniprot-proteome_Human_UP000005640_20191105.fasta` yields 539137 lines. First 4999
lines evenly splits between entries, and is ~1% of the file.

```bash
head -n 4999 example/uniprot-proteome_Human_UP000005640_20191105.fasta > tiny/tiny.fasta
```

Splitting the mzML file is more difficult due to XML formatting. One of the files 
`example/uniprot-proteome_Human_UP000005640_20191105.fasta` contains 78301 `<pectrum index>` fields.
We can subset by excluding the lines for 99% of the indices. If we only want ~700 of the indices,
we exclude indices 701-78301. Each field ends with a `</spectrum>` tag.

Based on pattern finding and line numbers, we want lines 1-(line BEFORE index 701, i.e. `<`) and from
(line CONTAINING `</spectrumList>`, i.e. `>=`) through EOF.

```bash
lower=$(grep -n '<spectrum index="701"' example/raw_MS_mzML/HREC_IRIS_1.mzML | cut -d ':' -f 1)
upper=$(grep -n '</spectrumList>' example/raw_MS_mzML/HREC_IRIS_1.mzML | cut -d ':' -f 1)
awk -v lower=${lower} \
    -v upper=${upper} \
    'NR < lower || NR >= upper' example/raw_MS_mzML/HREC_IRIS_1.mzML \
    > tiny/tiny.mxML
```

### Test run with container
```bash
src/tiny-diann-test.sh tiny/tiny.mxML tiny/tiny.fasta 
```

</details>
